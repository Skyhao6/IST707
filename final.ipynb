{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18506\n",
      "17424\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# traindata = pd.read_csv(\"D:\\\\Homework\\\\SU\\\\IST707\\\\final\\\\trainSet.csv\")\n",
    "# testdata = pd.read_csv(\"D:\\\\Homework\\\\SU\\\\IST707\\\\final\\\\testSet.csv\")\n",
    "# trainSet = pd.DataFrame(traindata)\n",
    "# testSet = pd.DataFrame(testdata)\n",
    "traindata = pd.read_csv(\"D:\\\\Homework\\\\SU\\\\IST707\\\\final\\\\Train_18507.csv\")\n",
    "trainSet = pd.DataFrame(traindata)\n",
    "\n",
    "# delete the first column\n",
    "trainSet = trainSet.drop(trainSet.columns[0], axis=1)\n",
    "print(len(trainSet))\n",
    "# If a row has missing value, drop it\n",
    "trainSet = trainSet.dropna(axis=0, how='any')\n",
    "print(len(trainSet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['country', 'age_group', 'travel_with', 'purpose', 'main_activity', 'info_source', 'first_trip_tz']\n"
     ]
    }
   ],
   "source": [
    "# 选出要pivot的列\n",
    "category_col = [\"country\",\"age_group\",\"travel_with\",\"purpose\",\"main_activity\",\"info_source\",\"first_trip_tz\"]\n",
    "print(category_col)\n",
    "# 循环遍历category_col，将他们都pivot\n",
    "for col in category_col:\n",
    "    # pandas内置函数get_dummies，把某一列的所有种类变成列\n",
    "    one_hot = pd.get_dummies(trainSet[col])\n",
    "    # 把每一个“种类列”加到dataframe最后，axis=1代表以列的形式加，axis=0是以行的形式\n",
    "    trainSet = pd.concat([trainSet, one_hot], axis=1)\n",
    "    # 把原来的pivot之前的列删掉\n",
    "    trainSet = trainSet.drop(col, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0    7014\n",
      "1.0    4058\n",
      "0.0    2867\n",
      "Name: cost_category, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# encode categories into numbers\n",
    "trainSet[trainSet.columns[0:]] = OrdinalEncoder().fit_transform(trainSet[trainSet.columns[0:]])\n",
    "\n",
    "# the distribution of the target variable cost_category\n",
    "trainSet['cost_category'].value_counts()\n",
    "# merge the cost_category from 0-1 to 0, 2-4 to 1\n",
    "\n",
    "trainSet['cost_category'] = trainSet['cost_category'].replace([0,1,2], 2)\n",
    "trainSet['cost_category'] = trainSet['cost_category'].replace([3,4], 0)\n",
    "trainSet['cost_category'] = trainSet['cost_category'].replace([5], 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(trainSet.drop('cost_category',axis=1),\n",
    "                                                    trainSet['cost_category'], test_size=0.20,\n",
    "                                                    random_state=101)\n",
    "\n",
    "# Print the distribution of y_test\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 把dataframe写成文件，输出到制定路径\n",
    "trainSet.to_csv(\"D:\\\\Homework\\\\SU\\\\IST707\\\\final\\\\PCA.csv\", index=False, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.4986665214866434\n",
      "Best Params:  {'dt__max_depth': 2, 'dt__min_samples_leaf': 4}\n",
      "Accuracy:  0.48948491313623893\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn import tree\n",
    "\n",
    "clf_dt = Pipeline([\n",
    "    ('dt', tree.DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'dt__max_depth':[2,5,10,15],\n",
    "    'dt__min_samples_leaf':[2,3,4,5,6,7,8,9,10]\n",
    "    }\n",
    "\n",
    "clf_dt = GridSearchCV(clf_dt, parameters, cv = 5)\n",
    "clf_dt.fit(X_train, y_train)\n",
    "print(\"Best Score:\", clf_dt.best_score_)\n",
    "print(\"Best Params: \", clf_dt.best_params_)\n",
    "print(\"Accuracy: \", clf_dt.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# Try different naive_bayes algorithm\n",
    "clf_nb = Pipeline([\n",
    "    #('standardscaler', StandardScaler()),\n",
    "    ('nb', naive_bayes.BernoulliNB())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    'nb__alpha':[0.5,1],\n",
    "    'nb__force_alpha':[True, False]\n",
    "}\n",
    "\n",
    "clf_nb = GridSearchCV(clf_nb, parameters, cv = 5)\n",
    "clf_nb.fit(X_train, y_train)\n",
    "print(\"Best Score:\", clf_nb.best_score_)\n",
    "print(\"Best Params: \", clf_nb.best_params_)\n",
    "print(\"Accuracy: \", clf_nb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'metric': 'manhattan', 'n_neighbors': 10, 'weights': 'distance'}\n",
      "KNeighborsClassifier(metric='manhattan', n_neighbors=10, weights='distance')\n",
      "0.40719292898506554\n"
     ]
    }
   ],
   "source": [
    "# kNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# maxAccuracy = 0\n",
    "# def train(k):\n",
    "#     clf = KNeighborsClassifier(n_neighbors = k)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     pred = clf.predict(X_test)\n",
    "#     return accuracy_score(y_test, pred)\n",
    "\n",
    "\n",
    "# for i in range(1,11):\n",
    "#     curAccuracy = train(i)\n",
    "#     if(curAccuracy > maxAccuracy):\n",
    "#         maxAccuracy = curAccuracy\n",
    "#         idx = i\n",
    "#     print(\"k =\",i,\"Accuracy = \",train(i))\n",
    "# print(\"Best Accuracy: \",maxAccuracy,\" k =\",idx)\n",
    "\n",
    "# Add parameter tuning to the model\n",
    "param_grid = {'n_neighbors': np.arange(1, 11, 1), 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']} \n",
    "# n_neighbors: number of neighbors to use\n",
    "# weights: weight function used in prediction\n",
    "# metric: the distance metric to use for the tree\n",
    "\n",
    "grid = GridSearchCV(KNeighborsClassifier(), param_grid, refit = True, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Print the accuracy of the best model\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM\n",
    "# SVM with Linear Kernel\n",
    "from sklearn import svm \n",
    "param_grid = {'C': [14,12], 'gamma': [0.001, 0.002], 'kernel': ['rbf']} \n",
    "# I also tested other parameters, but the accuracy is not better than the above parameters.  'poly', 'sigmoid' are not good.\n",
    "grid = GridSearchCV(svm.SVC(), param_grid, refit = True, cv=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "# Print the accuracy of the best model\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with Polynomial Kernel\n",
    "from sklearn import svm \n",
    "print(\"Without tuning parameters:\")\n",
    "clf_svm_poly = Pipeline([\n",
    "    ('standardscaler', StandardScaler()),\n",
    "    ('svc', svm.SVC(kernel='poly'))\n",
    "])\n",
    "# train_col = trainSet.columns[0:-1]\n",
    "# clf_svm_linear.fit(trainSet[train_col], trainSet[trainSet.columns[0]])\n",
    "# pred_svm_linear = clf_svm_linear.predict(testSet[testSet.columns[1:-1]])\n",
    "# pred = clf_svm_linear.predict(testSet[testSet.columns[1:-1]])\n",
    "# print(\"Accuracy: \",accuracy_score(testSet['cost_category'], pred))\n",
    "\n",
    "\n",
    "print(\"Add tuning parameters:\")\n",
    "parameters = {\n",
    "    'svc__C':np.arange(0.001,1.0, 0.05),\n",
    "    'svc__degree':[1,2,3],\n",
    "    'svc__gamma':[0.001, 0.01, 0.1, 0.5],\n",
    "    'svc__kernel':['poly',]\n",
    "    }\n",
    "clf_svm_poly = GridSearchCV(clf_svm_poly, parameters, cv = 5)\n",
    "clf_svm_poly.fit(X_train, y_train)\n",
    "print(\"Best Score:\", clf_svm_poly.best_score_)\n",
    "print(\"Best Params: \", clf_svm_poly.best_params_)\n",
    "print(\"Accuracy: \", clf_svm_poly.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVM with Radial Kernel\n",
    "from sklearn import svm \n",
    "print(\"Without tuning parameters:\")\n",
    "clf_svm_rad = Pipeline([\n",
    "    ('standardscaler', StandardScaler()),\n",
    "    ('svc', svm.SVC(kernel='rbf'))\n",
    "])\n",
    "parameters = {\n",
    "    'svc__C':[5,10,12],\n",
    "    'svc__gamma':[0.001, 0.002],\n",
    "    'svc__kernel':['rbf',]\n",
    "    }\n",
    "clf_svm_rad = GridSearchCV(clf_svm_rad, parameters, cv = 5)\n",
    "clf_svm_rad.fit(X_train, y_train)\n",
    "print(\"Best Score:\", clf_svm_rad.best_score_)\n",
    "print(\"Best Params: \", clf_svm_rad.best_params_)\n",
    "print(\"Accuracy: \", clf_svm_rad.score(X_test, y_test))\n",
    "\n",
    "# param_grid = {'C': [14,12], 'gamma': [0.001, 0.002], 'kernel': ['rbf']} \n",
    "# # I also tested other parameters, but the accuracy is not better than the above parameters.  'poly', 'sigmoid' are not good.\n",
    "# grid = GridSearchCV(svm.SVC(), param_grid, refit = True, cv=2)\n",
    "# grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "# Print the accuracy of the best model\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, grid_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-means Cluster\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "clf_km = Pipeline([\n",
    "    ('standardScaler', StandardScaler()),\n",
    "    ('km', KMeans())\n",
    "])\n",
    "parameters = {\n",
    "    'km__n_clusters':range(3, 8, 1),\n",
    "    #'km__algorithm':['lloyd', 'elkan']\n",
    "}\n",
    "clf_km = GridSearchCV(clf_km, parameters)\n",
    "clf_km.fit(X_train)\n",
    "print(\"Accuracy: \", clf_km.score(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'criterion': 'gini', 'max_depth': 10, 'n_estimators': 340}\n",
      "RandomForestClassifier(max_depth=10, n_estimators=340)\n",
      "0.48948491313623893\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "param_grid = {'n_estimators': range(290,350,10), 'max_depth': range(10,15,1), 'criterion': ['gini']} \n",
    "# I have tested a lot of parameters, the n_estimators value from 1 to 300, the max_depth value from 1 to 20, the criterion value from 'gini' to 'entropy'.\n",
    "grid = GridSearchCV(RandomForestClassifier(), param_grid, refit = True, cv=2)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print the best parameters\n",
    "print(grid.best_params_)\n",
    "print(grid.best_estimator_)\n",
    "\n",
    "# Print the accuracy of the best model\n",
    "grid_predictions = grid.predict(X_test)\n",
    "print(accuracy_score(y_test, grid_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
